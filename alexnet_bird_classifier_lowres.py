# -*- coding: utf-8 -*-
"""AlexNet-bird-classifier-lowres.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kLnugQ38degkdXhcuKKJ42mIjZhN9hTD
"""

import os
import cv2
import shutil
import random
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import DataLoader, Dataset
from torchvision.datasets import ImageFolder
from PIL import Image

"""# **1. 데이터셋 구성**"""

# 데이터 경로 지정하기
data_root = '/content/drive/MyDrive/[수업]컴퓨터비전/실습_DATA/조류 이미지 분류_이전'

# train.csv 불러오기
df = pd.read_csv(f'{data_root}/train.csv')
df.head()

# train.csv에 있는 label값 별로 비중 확인하기
df['label'].value_counts().sort_index(ascending=True)

# train.csv에 있는 label값들을 리스트화 시키기
labels = sorted(df['label'].unique())
labels

# label별로 train 하위폴더에 폴더 생성
train_root = f'{data_root}/train'

for label in labels:
  if not os.path.exists(f'{train_root}/{label}'):
    os.makedirs(f'{train_root}/{label}', esist_ok=True)

# train.csv의 img_path와 label값과 일치하는 폴더로 이미지 이동시키기
for i in range(len(df)):
  img_path = df.loc[i, 'img_path'].replace('./','')
  label = df.loc[i, 'label']
  shutil.move(f'{data_root}/{img_path}', f'{data_root}/train/{label}')

# 폴더별 이미지개수를 확인하여 기존 train.csv에서 확인한 값과 비교
for label in labels:
  files = os.listdir(f'{data_root}/train/{label}')
  print(f'{label} 이미지 개수: {len(files)}')

# label별로 빈도수 시각화 하기
plt.figure(figsize=(20, 6))
plt.bar(labels, [len(os.listdir(f'{data_root}/train/{label}')) for label in labels])
plt.title('Number of Images per Category')
plt.xlabel('labels')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.show

"""# **2. 데이터셋 분할**"""

# val폴더를 새로 생성하고, label별로 하위폴더 생성
val_root = f'{data_root}/val'
if not os.path.exists(val_root):
  os.makedirs(val_root, exist_ok=True)

for label in labels:
  if not os.path.exists(f'{val_root}/{label}'):
    os.makedirs(f'{val_root}/{label}', exist_ok=True)

# 기존 test폴더에는 label이 없으므로 임의로 자료 삭제 후
# test 폴더를 새로 생성하고, label별로 하위폴더 생성
test_root = f'{data_root}/test'
if not os.path.exists(test_root):
  os.makedirs(test_root, exist_ok=True)

for label in labels:
  if not os.path.exists(f'{test_root}/{label}'):
    os.makedirs(f'{test_root}/{label}', exist_ok=True)

random.seed(2004)

for label in labels:
    test_files = os.listdir(f'{test_root}/{label}')

    for file_name in test_files:
        # 파일이 이미 존재하면 이동하지 않음
        if not os.path.exists(f'{train_root}/{label}/{file_name}'):
            shutil.move(f'{test_root}/{label}/{file_name}', f'{train_root}/{label}/{file_name}')

# 폴더별 이미지개수를 확인하여 기존 train.csv에서 확인한 값과 비교
for label in labels:
  files = os.listdir(f'{data_root}/train/{label}')
  print(f'{label} 이미지 개수: {len(files)}')

# train에 있는 이미지를 random으로 val, test폴더로 이동시키기(train:val:test→7:1.5:1.5)
random.seed(2004)

for label in labels:
  file_list = os.listdir(f'{train_root}/{label}')
  random.shuffle(file_list)

  ratio = 0.15
  num_file = len(file_list)

  test_list = file_list[:int(num_file*ratio)]
  val_list = file_list[int(num_file*ratio):int(num_file*ratio*2)]
  train_list = file_list[int(num_file*ratio*2):]

  for test_name in test_list:
    shutil.move(f'{train_root}/{label}/{test_name}', f'{test_root}/{label}/{test_name}')

  for val_name in val_list:
    shutil.move(f'{train_root}/{label}/{val_name}', f'{val_root}/{label}/{val_name}')

# label별로 train, val, test의 개수 및 비율 출력해보기
for label in labels:
  train_files = os.listdir(f'{train_root}/{label}')
  val_files = os.listdir(f'{val_root}/{label}')
  test_files = os.listdir(f'{test_root}/{label}')
  print(f'{label}  train:{len(train_files)}, val:{len(val_files)}, test:{len(test_files)}, ',
        f'train_ratio:{len(train_files)/ (len(val_files)+len(train_files)+len(test_files))*100:.2f}%, ',
        f'val_ratio:{len(val_files)/ (len(val_files)+len(train_files)+len(test_files))*100:.2f}%, ',
        f'test_ratio:{len(test_files)/ (len(val_files)+len(train_files)+len(test_files))*100:.2f}%')

"""# **이미지 전처리**"""

# 이미지 열기
img = Image.open(f'{data_root}/train/Asian Green Bee-Eater/TRAIN_00086.jpg')

print(img.size)

plt.imshow(img)
plt.axis('off')  # 축을 숨김
plt.show()

# 다양한 보간법을 사용하여 리사이즈

names = ['NEAREST', 'BOX', 'BILINEAR', 'HAMMING', 'BICUBIC', 'LANCZOS']
methods = [Image.Resampling.NEAREST, Image.Resampling.BOX, Image.Resampling.BILINEAR,
           Image.Resampling.HAMMING, Image.Resampling.BICUBIC, Image.Resampling.LANCZOS]

plt.figure(figsize=(12, 8))
for idx, (name, method) in enumerate(zip(names, methods)):
  dst = img.resize((400,400), method)
  plt.subplot(2, 3, idx+1)
  plt.imshow(dst)
  plt.title(name)
  plt.axis('off')
plt.show()

transform = transforms.Compose([
    transforms.Resize((224, 224), interpolation=Image.Resampling.LANCZOS),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = ImageFolder(train_root, transform=transform)
val_dataset = ImageFolder(val_root, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)

# AlexNet 모델
model = models.alexnet(pretrained=True)
model

for param in model.parameters():
  param.requires_grad = False

# label이 25종류여서 해당 부분 수정
model.classifier[6] = nn.Linear(4096, 25)

# 5, 6부분을 학습에 참여를 시키기로 하여 다음과 같은 코드를 생성
model.classifier[5].requires_grad = True
model.classifier[6].requires_grad = True

model

loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# 모델의 정확도 계산 함수 생성
def calculate_accuracy(loader, model):
  model.eval()
  correct = 0
  total = 0
  with torch.no_grad():
    for data in loader:
      images, labels = data
      images, labels = images.to(device), labels.to(device)
      outputs =model(images)
      _, predicted = torch.max(outputs.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
    return 100 * correct / total

train_losses = []
val_losses = []
val_accuracies = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device



num_epochs = 20

model = model.to(device)

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_loss = running_loss / len(train_loader)
    train_losses.append(train_loss)
    val_loss = 0.0
    model.eval()
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = loss_func(outputs, labels)
            val_loss += loss.item()
    val_loss /= len(val_loader)
    val_losses.append(val_loss)
    val_accuracy = calculate_accuracy(val_loader, model)
    val_accuracies.append(val_accuracy)
    print(f'Epoch {epoch + 1}, Train Loss: {train_loss: .6f}, Val Loss: {val_loss: .6f}, Val Accuracy: {val_accuracy: .2f}%')

plt.figure(figsize=(15, 5))
# 학습 손실 그래프
plt.subplot(1, 3, 1)
plt.plot(train_losses, label='Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()
# 검증 손실 그래프
plt.subplot(1, 3, 2)
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Validation Loss Over Epochs')
plt.legend()
# 검증 정확도 그래프
plt.subplot(1, 3, 3)
plt.plot(val_accuracies, label='Validation Accuracy', color='orange')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy Over Epochs')
plt.legend()
plt.tight_layout()
plt.show()

def load_and_transform_image(image_path, transform):
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)

labels = sorted(df['label'].unique())

labels

# test결과 값 시각화
plt.figure(figsize=(25, 25))
counter = 1
for label in labels:
  img_names = os.listdir(f'{data_root}/test/{label}')
  # test파일에 있는 값을 섞은 뒤 첫번째 이미지를 뽑는다
  random.shuffle(img_names)
  selected_img = img_names[0]

  img_path = f'{data_root}/test/{label}/{selected_img}'
  image = load_and_transform_image(img_path, transform)
  image = image.to(device)

  model.eval()
  with torch.no_grad():
      outputs = model(image)
      _, predicted = torch.max(outputs, 1)
  prediction = labels[predicted.item()]
  plt.subplot(5, 5, counter)
  plt.imshow(Image.open(img_path))
  plt.title(f'True: {label}, Pred: {prediction}')
  plt.axis('off')
  counter += 1

plt.tight_layout()
plt.show()